{
  "hash": "aa6b257f46255dc73d715f3b437c7c2a",
  "result": {
    "markdown": "---\ntitle: '[DRAFT] A few million tasks that Pythia can do'\ndate: 6/12/2023\nformat:\n  html:\n    grid:\n      margin-width: 350px\n  ipynb: default\nreference-location: margin\ncitation-location: margin\nbibliography: skeleton.bib\nexecute:\n  echo: false\n---\n\n## Introduction\n\nMuch of mechanistic interpretability either:\n\n1. Focuses on toy tasks in toy models. (footnote: not a bad thing) (cite a bunch of examples, transformer circuits, other toy work, sparse transformers, jermyn paper)\n2. Focuses on a small dataset of realistic prompts applied to a real model.  (IOI, alpaca das, rome, acdc, greater-than, ...). \n\nTo add a new approach, we would like to scale up interpretability methods to a large dataset of tasks focused on real models.  \n\nTo that end, we're sharing two datasets:\n\n1. a dataset of token-bigram and token-trigram statistics from The Pile (CITE) including tables of one and two token prompts with their most likely completions. \n2. an input scanning dataset that uses the Pythia 1.4B model to determine what tokens are extremely predictive in context.\n\n### Bigrams and Trigrams\n\nWe process the entire deduplicated Pile for bigram and trigram counts. [link to the code for a further description of the construction of the dataset]... \n\n### Input scanning\n\nAn unsupervised method for identifying millions of different things that a model knows. \n\nWe scan through the pre-training corpus ${t_0,...,t_N}$ and compare the output of the model on a pair of prompts:\n- $p_0  = [t_i, ... t_{i + n}]$ is a contiguous $n$-token prompt from the pre-training corpus.\n- $p_1  = [t_{i-1}, t_i, ... t_{i + n}]$ is an $(n+1)$-token prompt where an additional token, $t_{i-1}$ has been added in the backwards direction in the text.\nWhen $M(p_1)$ differs substantially from $M(p_0)$, we capture the two prompts as a \"task\" that the model has succeeded at regardless of whether the model is correct or not. To be more precise, we accept the task if:\n$$\\mathrm{JSD}(M(p_1), M(p_2)) > 0.5$$\nwhere JSD is the [Jensen-Shannon Divergence](https://en.wikipedia.org/wiki/Jensenâ€“Shannon_divergence). By focusing on tasks for which the addition of $t_{i - 1}$ to the prompt had a large influence, we expect to find \n\nExamples of input\n\n### What we're using these datasets for?\nThere's a lot we want to do with this data. \n- Producing a mechanistic map of a model's internals:\n\t- Mapping out the features and circuits responsible for each task. \n\t- Are there patterns to \n\t- This map will \n- Using the dataset as a benchmark for automated circuit identification algorithms like (ACDC, boundless DAS). \n- Look for inputs that activate portions of the network for which we don't have any activators yet. \n- Finding examples of superposition in the wild. The number of tasks available via input scanning exceeds the number of multilayer perceptron neurons in Pythia 2.8B. Therefore, we may be able to find directions in activation space that interfere.\n\n### TODO:\n\n- List lots of facts about the data: number of rows, number of bigrams/trigrams, percent that are highly predictive. graphs of the data.\n- Present a page-able interactive data viewer.\n- warn about the token bigrams that tokenize as a single token.\n\n\n\n\n```{ojs}\n\ndata = FileAttachment(\"palmer-penguins.csv\").csv({ typed: true })\nfiltered = data.filter(function(penguin) {\n  return bill_length_min < penguin.bill_length_mm &&\n         islands.includes(penguin.island);\n})\nInputs.table(filtered)\n```\n\n```{ojs}\n//| panel: input\nviewof bill_length_min = Inputs.range(\n  [32, 50], \n  {value: 35, step: 1, label: \"Bill length (min):\"}\n)\nviewof islands = Inputs.checkbox(\n  [\"Torgersen\", \"Biscoe\", \"Dream\"], \n  { value: [\"Torgersen\", \"Biscoe\"], \n    label: \"Islands:\"\n  }\n)\n```\n\n```{ojs}\nPlot.rectY(filtered, \n  Plot.binX(\n    {y: \"count\"}, \n    {x: \"body_mass_g\", fill: \"species\", thresholds: 20}\n  ))\n  .plot({\n    facet: {\n      data: filtered,\n      x: \"sex\",\n      y: \"species\",\n      marginRight: 80\n    },\n    marks: [\n      Plot.frame(),\n    ]\n  }\n)\n```\n\n---\njupyter:\n  kernelspec:\n    display_name: Python 3 (ipykernel)\n    language: python\n    name: python3\n---\n",
    "supporting": [
      "obvious_completions_files/figure-ipynb"
    ],
    "filters": []
  }
}